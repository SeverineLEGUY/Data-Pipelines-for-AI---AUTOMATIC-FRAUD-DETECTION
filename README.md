# üöÄ D√©tection Automatique de Fraude : Pipeline Airflow

## üéØ Objectif du Projet

Ce projet impl√©mente une solution d'**Orchestration de Workflows** utilisant **Apache Airflow** pour la d√©tection quotidienne et le reporting de transactions potentiellement frauduleuses. Il simule un environnement de production en :

1.  Stockant un jeu de donn√©es massives (555k transactions) dans une base de donn√©es **PostgreSQL**.
2.  Ex√©cutant un **DAG** (`daily_fraud_report_pipeline`) qui interroge la base pour les transactions frauduleuses d√©tect√©es la veille.
3.  G√©n√©rant un rapport et en l'envoyant par e-mail.

### Technologies Cl√©s

* **Orchestration :** Apache Airflow
* **Conteneurisation :** Docker & Docker Compose
* **Base de Donn√©es :** PostgreSQL
* **Data Pipelining :** Python, Pandas

---

## üì¶ Architecture et Services

L'environnement est enti√®rement conteneuris√©. Les services sont lanc√©s via `docker-compose.yml`.

| Service Docker | R√¥le | Port d'Acc√®s |
| :--- | :--- | :--- |
| `airflow-webserver` | Interface Utilisateur d'Airflow (UI) | `http://localhost:8081` |
| `airflow-scheduler` | Planifie et monitore les DAGs | N/A |
| `airflow-airflow-worker-1` | Ex√©cute les t√¢ches distribu√©es | N/A |
| `airflow-postgres-1` | Base de donn√©es pour Airflow (metadata) et les donn√©es m√©tier | 5432 (interne) |
| `airflow-redis-1` | Broker de messages pour Airflow (Celery Executor) | N/A |

---

## üõ† Pr√©requis

* **Docker Desktop** (install√© et en cours d'ex√©cution).
* **Cloner** ce d√©p√¥t Git.

---

## üìå 1. D√©marrage de l'Environnement

### 1.1 Lancer les conteneurs

Dans le r√©pertoire racine du projet (contenant le `docker-compose.yml`), ex√©cutez les commandes suivantes :

```bash
# 1. Initialiser la base de donn√©es Airflow
docker-compose up airflow-init

# 2. D√©marrer l'ensemble des services en arri√®re-plan
docker-compose up -d --force-recreate
---
Le flag `--force-recreate` garantit un red√©marrage propre des services Airflow.

### 1.2 Acc√®s √† Airflow

Ouvrez votre navigateur et acc√©dez √† : **`http://localhost:8081`**
Identifiants par d√©faut : `airflow` / `airflow` (si configur√©).

---

## üìå 2. Initialisation des Donn√©es

Vous devez ex√©cuter le script `insert_data-db.py` pour remplir la base de donn√©es m√©tier. Ce script utilise le chargement par lots et date les donn√©es √† la veille pour permettre un test imm√©diat du DAG.

1.  **Copiez les fichiers** dans le conteneur worker :
    ```bash
    docker cp fraudTest.csv airflow-airflow-worker-1:/opt/airflow/data/
    docker cp insert_data-db.py airflow-airflow-worker-1:/opt/airflow/data/
    ```

2.  **Ex√©cutez le script** d'initialisation dans le conteneur :
    ```bash
    docker exec -it airflow-airflow-worker-1 /bin/bash
    
    # Dans le conteneur :
    cd /opt/airflow/data
    export PROD_DB_URI="postgresql://airflow:airflow@airflow-postgres-1:5432/airflow" 
    python insert_data-db.py
    exit # Quitter le conteneur
    ```
    Confirmez le message de succ√®s : ‚úÖ Toutes les donn√©es ont √©t√© charg√©es (555719 lignes) et les tables initialis√©es avec succ√®s.

---

## üìå 3. Configuration des Connexions Airflow

### 3.1 Connexion PostgreSQL (Base M√©tier)

Cr√©ez cette connexion dans l'Airflow UI (**Admin** > **Connections**) :

* **Conn Id :** `NEON_DB`
* **Conn Type :** `Postgres`
* **Host :** `airflow-postgres-1` (Nom du service Docker)
* **Schema :** `airflow`
* **Login :** `airflow`
* **Password :** `airflow`
* **Port :** `5432`

### 3.2 Variables d'Environnement (E-mail)

Cr√©ez ces variables dans l'Airflow UI (**Admin** > **Variables**) pour la t√¢che d'envoi d'e-mail :

| Cl√© (Key) | Description |
| :--- | :--- |
| `SENDER_EMAIL` | Votre adresse Gmail utilis√©e pour l'envoi. |
| `APP_PASSWORD` | Le Mot de Passe d'Application g√©n√©r√© par Google. |
| `RECEIVER_EMAIL` | L'adresse de destination du rapport. |

---

## üìå 4. D√©clenchement du DAG

Une fois la configuration termin√©e, allez √† l'Airflow UI :

1.  Trouvez le DAG **`daily_fraud_report_pipeline`**.
2.  Activez-le.
3.  D√©clenchez une ex√©cution manuelle.

### Flux du Pipeline

| T√¢che (Task ID) | R√¥le |
| :--- | :--- |
| `create_daily_fraud_report` | Se connecte √† la BDD via `NEON_DB`, interroge la table `fraud_predictions` pour la veille, g√©n√®re le rapport et le pousse vers XCom. |
| `send_daily_report_email` | R√©cup√®re le rapport via XCom et envoie l'e-mail √† l'adresse sp√©cifi√©e dans les Variables Airflow. |

---

## üìå 5. Arr√™t de l'Environnement

Pour arr√™ter proprement et conserver vos volumes de donn√©es persistants :

```bash
docker-compose down